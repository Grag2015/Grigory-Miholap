Подробнее обо мне:

**1. Резюме**  
Здесь [мое резюме](http://jobs.tut.by/resume/69a58361ff02a111a30039ed1f794e66434f43)

**2. Английский**

Intermediate - на данный момент посещаю курсы Белхарда.  
[сертификат](https://yadi.sk/i/CZigBEAjoy9f6) pre-Intermediate (B1)  
  

**3. Опыт анализа данных**  

Выполненные работы:

1) Построение линейной модели для оценки стоимости жилой недвижимости (вторичный рынок, Минск) [приложение](https://grag2015.shinyapps.io/property2/)

2) Построение линейной модели для прогнозирования продаж мороженного в зависимости от погоды
см. отчет [Анализ данных](https://github.com/Grag2015/ice-cream/blob/master/9_Weather/Analys_Sales_Weather_TOP.md) 

3) Участие в соревнованиях по машинному обучению (machine learning) Kaggle [результаты](https://www.kaggle.com/grag2015/results)

Пройденные курсы:  
Курс 1.  [обработка данных с помощью R](https://www.coursera.org/specializations/jhudatascience)  
Прикрепляю для примера несколько выполненных мной отчетов:   
а) зачетная работа по курсу "воспроизводимые исследования" [ссылка](https://github.com/Grag2015/Coursera/blob/master/4_Reproducible%20Research/RepData_PeerAssessment2/StormData_analysis.md)  
б) зачетная работа по курсу "статистические выводы"   [часть1](https://github.com/Grag2015/Coursera/blob/master/5_Statistical%20Inference/Assessment1_part1.md) и [часть2](https://github.com/Grag2015/Coursera/blob/master/5_Statistical%20Inference/Assessment1_part2.md)  
в) зачетная работа по курсу "машинное обучение" [ссылка](http://htmlpreview.github.io/?https://github.com/Grag2015/Coursera/blob/master/7_Machine%20Learning/Course_project2.html)  
Курс 2. Основы статистики [сертификат](https://stepic.org/certificate/121f708b0704c6aa633a4725459bb867c3dad996.pdf)  
Курс 3. Статистическая обработки данных с помощью R [сертификат](https://stepic.org/certificate/35e817e40802f50e366699ead6981bbacedf26b9.pdf)  


В настоящее время прохожу 2 онлайн-курса от Яндекса по машинному обучению  
[https://www.coursera.org/learn/vvedenie-mashinnoe-obuchenie/](https://www.coursera.org/learn/vvedenie-mashinnoe-obuchenie/)  
[https://www.coursera.org/learn/mathematics-and-python](https://www.coursera.org/learn/mathematics-and-python)

Примеры выполненных заданий:  

Задание 1. [Анализ связи между количеством покупок на уровне, сложностью и оттоком.](http://htmlpreview.github.io/?https://github.com/Grag2015/testInfotech/blob/master/Task_1_match-3.html)  
Задание 2. [Анализ результатов А/Б-тестирования](http://htmlpreview.github.io/?https://github.com/Grag2015/testInfotech/blob/master/Task_3_AB-test.html)  
Задание 3. [Прогнозирование эффективности каналов привлечения пользователей](http://htmlpreview.github.io/?https://github.com/Grag2015/testInfotech/blob/master/Task_2_advert_channels.html)  
Задание 4. [Анализ жалобы от пассажиров на плохую работу транспорта](http://htmlpreview.github.io/?https://github.com/Grag2015/testWG/blob/master/Task_2_Minsktrans.html)   

Задание 5. [Анализ поведения пользователей в игре](http://htmlpreview.github.io/?https://github.com/Grag2015/test_Playrix/blob/master/playrix_test.html)

**Дополнительно.**   
**практический опыт связанный с анализом и обработкой данных:**   

4.1. Следующий пример демонстрирует уровень владения языком программирования VBA и навыки работы с СУБД (проектирование реляционных БД, язык запросов SQL). задача: Проектирование и разработка приложения на базе MS ACCESS для автоматизации работы по кодированию данных мониторинга рекламы в печатных СМИ (задача приложения – хранить данные мониторинга рекламы, предоставлять пользователю интерфейс для работы с данными(внесение, удаления, редактирование), предоставлять администратору интерфейс для агрегации данных полученных от нескольких пользователей, проверка целостности и непротиворечивости данных); пример базы в формате ACCESS можно скачать по ссылке https://yadi.sk/d/5VxUhOwdiYXD9 Используя данный инструмент командой из 10 человек было оцифровано порядка 50 тыс. рекламных сообщений в печатных СМИ Беларуси. Результаты работы команды публиковались на тематических ресурсах, например. http://marketing.by/novosti-rynka/soglasno-issledovaniyu-monitoringovoy-kompanii-media-inteligence-obem-rynka-reklamy-v-pechatnykh-smi-v-2009-godu-sostavil-okolo-16-4-mln/  

4.2. При разработке утилит для отдела SEO решали задачи классификации вебстраниц (по заданным типам). (все указанные ниже материалы можно скачать в архиве по [ссылке](https://yadi.sk/d/SkM-ZqkEiYYh6))
Классы веб-страниц, анализируемые параметры и алгоритм классификации описан в файле "Теоретическая схема 
определения типа Web2.docs".
Полный список анализируемых параметров - в файле "Техническое задание_Параметры"
Обучающая и экзаменационная выборка - в файлах "*** выборка"
Наибольшую проблему при определении
класса страницы создавали ошибки при получении параметров, особенно касающихся видео на веб-страницах.
(проблемы с видео связаны с многообразием вариантов кода вставки видео и "видимостью" данного кода для парсера.)
В результате обучения дерева решений удалось достичь точности определения 
типа страниц на уровне 70%. Однако для практического использования этого
результата оказалось недостаточно.   

4.3. Есть опыт разработки алгоритмов оптимизации.  
Разработал математический алгоритм для решения задачи линейного раскроя материалов на множестве целых чисел. Нашел алгоритм линейного раскроя материалов Канторовича Л.В. для вещественных чисел, адаптировал
его для целочисленных решений добавив алгоритм решения классической задачи о рюкзаке. Далеее этот алгоритм был полностью реализован и отлажен мной в пакете Mathematics, и переписан программистом на С++. В результате внедрения отходы раскроя снизились с 5-7% до 2-3%.  

4.4. Во время работе по настройке информационно-аналитической системы получил опыт анализа слабоструктурированной информации - содержимого веб-страниц (в частности текстов на естественном языке). А именно настраивал для информационно-поисковой системы краулер для парсинга веб-страниц и извлечения полезной информации (даты новости, тайтла, автора, текста), а также настраивал модуль для фактографического анализа текста, который позволял извлекать факты из текста, например из новостей о поставках вооружения извлекались такие сущности - страна-поставщик, страна-покупатель, виды вооружения, объемы и сумма закупок и связи между этими сущностями
